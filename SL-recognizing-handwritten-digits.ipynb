{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img src=\".github./images/MNIST.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektna naloga pri predmetu TZ - Tehnologije Znanja\n",
    "## Klasifikacija slik - ročno napisanih števk\n",
    "* 60.000 števk\n",
    "* 28×28 pikslov\n",
    "* sivine\n",
    "### Primerjava algoritmov nevronskih mrež s točnostmi, podanih na spletni strani\n",
    "* Čas\n",
    "* Število layerjev\n",
    "* Število epoch\n",
    "* Navzkrižna validacija\n",
    "* Različni algoritmi\n",
    "#### Podatki dostopni na  [MNIST Image Databse](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Najboljša zadeva pri reševanju \"problema\" MNIST je ta, da ne potrebujemo najbolšega računalnika na trgu, pravzaprav ne ptorebujemo niti grafične kartice. Modeli bi se naj s pomočjo CPUja v povprečju natrenirali približno v minuti, dejanske čase si bomo ogledali tekom tega doumenta. To raziskovalcu olajša delo, manj je čakanja, hkrati pa lahko eksperimentiramo z algoritmi, navzkrižno validacijo ipd.\n",
    "\n",
    "Moj cilj je torej doseči čim večjo točnost v čim krajšem času. Primerjali bomo gole algoritme, večina njihovih parametrov bo nastavljena na privzete vrednosti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Za delo potrebujemo različne knjižnice. V kolikor še niso nameščene, pred začetkom dela poženemo naslednje komande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# pip install python-mnist # Če bi na drugačen način nalagali podatke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## idx3\n",
    "Zaradi manjše velikosti so sličice podane v datoteki s končnico '.idx3-ubyte'\n",
    "\n",
    "To je preprost format za shranjevanje vektorjev ter multi-dimenzionalnih matrik, ki vključujejo različne numerične tipe (spremenljivk).\n",
    "\n",
    "Zato je prva naloga, da slikice iz te datoteke spravimo v berljivo obliko ter si jih ogledamo\n",
    "* Slike za učenje so v mapi /train \n",
    "* Slike za testiranje so v mapi /test\n",
    "_________________\n",
    "Datoteke:\n",
    "* train-images.idx3-ubyte\n",
    "* train-labels.idx1-ubyte\n",
    "* t10k-images.idx3-ubyte\n",
    "* t10k-labels.idx1-ubyte\n",
    "_________________\n",
    "\n",
    "Primer zapisa slik v datoteko\n",
    "\n",
    "| Offset | Type          | Value            | Description              |\n",
    "|--------|---------------|------------------|--------------------------|\n",
    "| 0000   | 32bit integer | 0x00000803(2051) | Magic Number (MSB first) |\n",
    "| 0004   | 32bit integer | 60000            | No. of items             |\n",
    "| 0008   | unsigned byte | 28               | No. of rows              |\n",
    "| 00012  | unsigned byte | 28               | No. of columns           |\n",
    "| 00016  |               | ??               | pixel                    |\n",
    "| 00017  |               | ??               | pixel                    |\n",
    "| ...    |               |                  |                          |\n",
    "| xxxx   |               | ??               | pixel                    |\n",
    "\n",
    "_________________\n",
    "Primer zapisa labelov v datoteko\n",
    "\n",
    "| Offset | Type          | Value            | Description              |\n",
    "|--------|---------------|------------------|--------------------------|\n",
    "| 0000   | 32bit integer | 0x00000801(2049) | Magic Number (MSB first) |\n",
    "| 0004   | 32bit integer | 60000            | No. of items             |\n",
    "| 0008   | unsigned byte | ??               | label                    |\n",
    "| 0009   | unsigned byte | ??               | label                    |\n",
    "| ...    |               |                  | label                    |\n",
    "| xxxx   |               | ??               |                          |\n",
    "The labels values are 0 to 9. \n",
    "\n",
    "*****\n",
    "Oglejmo si našo kodo začnimo pri podatkih slikovnih datotek. Podobno kot s for zanko, gremo skozi datoteko. Prve 4 spremenljivke (razvidno iz tabele):\n",
    "* Magic Number\n",
    "* Velikost (Size)\n",
    "* Število vrstic (nrows)\n",
    "* Število stolpcev (ncols)\n",
    "\n",
    "Vsaka naslednja pa predstavlja pixel 28*28 slike - 784 pikslov. Avtor je pokazal, da je takšna slika dovolj natančna, da predstavlja ročno napisano števko\n",
    "\n",
    "Podoben začetek je pri labelih, prvi 2 vrstici predstavjata:\n",
    "* Magic Number\n",
    "* Velikost (Size)\n",
    "\n",
    "Vsak naslednji vnos v datoteko pa je label slike, torej števka med 0 in 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from os import path\n",
    "\n",
    "\n",
    "# če datoteka ne obstaja, unzip\n",
    "if not path.exists(\"train/train-images.idx1-ubyte\"):\n",
    "    with zipfile.ZipFile(\"train/train-images.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "\n",
    "def preberiDatoteke():\n",
    "    with open(\"train/train-images.idx3-ubyte\", \"rb\") as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "        train_data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
    "        train_data = train_data.reshape((size, nrows, ncols))\n",
    "\n",
    "    with open(\"train/train-labels.idx1-ubyte\", \"rb\") as i:\n",
    "        magic, size = struct.unpack(\">II\", i.read(8))\n",
    "        train_data_labels = np.fromfile(i, dtype=np.dtype(np.uint8)).newbyteorder(\">\")\n",
    "\n",
    "    with open(\"test/t10k-images.idx3-ubyte\", \"rb\") as j:\n",
    "        magic, size = struct.unpack(\">II\", j.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", j.read(8))\n",
    "        test_data = np.fromfile(j, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
    "        test_data = test_data.reshape((size, nrows, ncols))\n",
    "\n",
    "    with open(\"test/t10k-labels.idx1-ubyte\", \"rb\") as k:\n",
    "        magic, size = struct.unpack(\">II\", k.read(8))\n",
    "        test_data_labels = np.fromfile(k, dtype=np.dtype(np.uint8)).newbyteorder(\">\")\n",
    "\n",
    "    return train_data, train_data_labels, test_data, test_data_labels\n",
    "\n",
    "\n",
    "(\n",
    "    train_data,\n",
    "    train_data_labels,\n",
    "    test_data,\n",
    "    test_data_labels,\n",
    ") = preberiDatoteke()  # Teh ne spreminjamo, da lahko kasneje ponastavimo\n",
    "x_train, y_train, x_test, y_test = preberiDatoteke()  # Na teh izvajamo naše operacije\n",
    "\n",
    "print(\"Število učnih slik:%8s\" % str(len(x_train)))\n",
    "print(\"Št. testnih slik:%10s\" % str(len(x_test)))\n",
    "print(\"Št. učnih labelov:%9s\" % str(len(y_train)))\n",
    "print(\"Št. test labelov:%10s\" % str(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Ti podatki so se veliko uporabljali, omogočajo različne vključitve v kodo\n",
    "\n",
    "Kot zanimivost si oglejmo velikosti arhivov ter velikost datotek po tem, ko jih odpakiramo\n",
    "* 9681 KB --> 45938 KB Slike Train\n",
    "* 1611 KB --> 7657 KB Slike Test\n",
    "* 29 KB --> 59 KB Labels Train\n",
    "* 5 KB --> 10 Labels Test\n",
    "\n",
    "Opazimo ~4-5kratno razliko\n",
    "\n",
    "Ravno zaradi popularnosti tega dataseta obstaja mnogo različnih načinov nalaganja podatkov, eden izmed najbolj preprostih je knjižnica python-mnist, ki nam podatke sama poda v spremenljivke \n",
    "* xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Več možnosti nalaganja dataseta\n",
    "* Obstaja knjižnica mnist\n",
    "* Zaradi popularnosti je ta set vključen v TensorFlow\n",
    "* Prenso datotek s pomočjo wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# pip install python-mnist\n",
    "## example of loading the mnist dataset\n",
    "# from keras.datasets import mnist\n",
    "# from matplotlib import pyplot\n",
    "## load dataset\n",
    "# (trainX, trainy), (testX, testy) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# !wget -O data/train-images-idx3-ubyte.gz http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "# !wget -O data/train-labels-idx1-ubyte.gz http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "# !wget -O data/t10k-images-idx3-ubyte.gz http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "# !wget -O data/t10k-labels-idx1-ubyte.gz http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Da potrdimo pravilno naložene podatke ter si jih hkrati vizualiziramo, uporabim knjižnico matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Primer števil iz dataseta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_data[i, :, :], cmap=\"gray\")\n",
    "    plt.title(train_data_labels[i])\n",
    "plt.show()\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_data[i, :, :], cmap=plt.cm.binary)\n",
    "    plt.title(train_data_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vidimo bele števke na črni podlagi. Kljub temu pa lahko uporabimo drugačne barve za njihov prikaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_data[59999])  # Vnesemo poljubno št med 0 in 59.999\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(20):\n",
    "    ax = plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(x_train[i, :, :])\n",
    "    plt.title(y_train[i])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train: X=%s, Y=%s\" % (x_train.shape, y_train.shape))\n",
    "print(\"Test:  x=%s, y=%s\" % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ogled poljubne slike in labela iz učne množice\n",
    "### Števko si lahko vizualiziramo na mnogo načinov, nekaj primerov je podanih spodaj (cmap='barvniFilter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "image_index = 1  # Vnesemo poljubno št med 0 in 59.999\n",
    "print(train_data_labels[image_index])\n",
    "# plt.imshow(train_data[image_index], cmap='Accent_r')\n",
    "# plt.imshow(train_data[image_index], cmap='flag')\n",
    "plt.imshow(train_data[image_index], cmap=\"summer\")\n",
    "# plt.imshow(train_data[image_index], cmap='winter')\n",
    "# plt.imshow(train_data[image_index], cmap='Dark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "\n",
    "\n",
    "def ponastaviPodatke(train_data, train_data_labels, test_data, test_data_labels):\n",
    "    x_train, y_train, x_test, y_test = (\n",
    "        train_data,\n",
    "        train_data_labels,\n",
    "        test_data,\n",
    "        test_data_labels,\n",
    "    )\n",
    "    # Preoblikovanje arrayev v 4-dimenzije, saj Keras sprejema takšne podatke\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    # Vrednosti morajo biti tipa float, da lahko po delitvi - standardizaciji pridobimo decimalne vrednosti\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "    # Normaliziramo - Standardiziramo RGB zapis slike, delimo z maksimalno vrednostjo RGB, kar je 255\n",
    "    # Standardizacija slike - vrednosti v arrayu med števila 0-1\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Importanje potrebnih modulov za tensorflow, Keras, potrebne layerje ipd.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sestava modela \n",
    "Moj plan je bil sestavo modela prikazati s sliko, ki je ustvarjena s pomočjo tf.keras.utils.plot_model() funkcije, vendar zaradi buga ne dela. Prav tako StackOverFlow nima rešitve, ki bi delovala pri meni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Sestavimo model Nevronske Mreže\n",
    "def SestaviModelKFold():\n",
    "    # Sekvenčni model - Po definiciji iz Keras odkumentacije je to linearen sklad slojev. To pomeni, da gredo naši podatki skozi sloje po vrstnem redu, tako, kot smo jih dodajali\n",
    "    modelKFold = Sequential()\n",
    "    modelKFold.add(\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            input_shape=input_shape,\n",
    "        )\n",
    "    )\n",
    "    modelKFold.add(MaxPooling2D((2, 2)))\n",
    "    modelKFold.add(Flatten())  # Sploščitev slojev, za boljšo povezavo med njimi\n",
    "    modelKFold.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    modelKFold.add(Dense(10, activation=\"softmax\"))\n",
    "    return modelKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizatorji \n",
    "Keras ima različne možnosti, najpogosteje pa se uporablja 'adam'. V naslednjem primeru bom uporabil SGD - Stochastic gradient descent, ki dobro deluje na plitvih nevronskih mrežah\n",
    "\n",
    "Dodatno mu dodamo še 'nesterov=True', Nesterov momentum oziroma NAG - Nesterov accelerated gradient. Kaj to sploh je?\n",
    "\n",
    "Momentum upošteva pretekle naklone - gradiente v račun, na podlagi česar izravnava korake med spuščanjem gradienta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Dodamo optimizator\n",
    "opt = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "modelKFold = SestaviModelKFold()\n",
    "modelKFold.summary()\n",
    "\n",
    "# Skompiliramo model\n",
    "modelKFold.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 98.250\n",
      "> 98.858\n",
      "> 99.417\n"
     ]
    }
   ],
   "source": [
    "# ocenitev našega modela na podlagi k-fold kros-validacije (k-fold cross-validation)\n",
    "n_folds = 5  # \"Poljubno\" nastavi\n",
    "epochsKFold = 2  # \"Poljubno\" nastavi\n",
    "scores = list()\n",
    "histories = list()\n",
    "\n",
    "x_train, y_train, x_test, y_test = ponastaviPodatke(\n",
    "    train_data, train_data_labels, test_data, test_data_labels\n",
    ")\n",
    "\n",
    "Ytrain = tf.keras.utils.to_categorical(y_train)\n",
    "Ytest = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "# Zmerimo čas\n",
    "CasZacetek = time.time()\n",
    "# razdelimo množice, navzkrižna validacija\n",
    "for train_x, test_x in kfold.split(x_train):\n",
    "    trainX = x_train[train_x]\n",
    "    trainY = Ytrain[train_x]\n",
    "    testX = x_train[test_x]\n",
    "    testY = Ytrain[test_x]\n",
    "    # natreniramo model v vsaki iteraciji for zanke znova\n",
    "    history = modelKFold.fit(\n",
    "        trainX,\n",
    "        trainY,\n",
    "        epochs=epochsKFold,\n",
    "        batch_size=32,\n",
    "        validation_data=(testX, testY),\n",
    "        verbose=0,\n",
    "    )\n",
    "    _, acc = modelKFold.evaluate(testX, testY, verbose=0)\n",
    "    print(\"> %.3f\" % (acc * 100.0))\n",
    "    scores.append(acc)\n",
    "    histories.append(history)\n",
    "\n",
    "print(\n",
    "    \"Točnost - accuracy: mean=%.3f std=%.3f, n_folds=%d\"\n",
    "    % (mean(scores) * 100, std(scores) * 100, n_folds)\n",
    ")\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "podatki = {\n",
    "    \"Ime\": [\"ModelKFold\"],\n",
    "    \"Tocnost\": mean(scores) * 100,\n",
    "    \"Loss\": mean(history.history[\"loss\"]) * 100,\n",
    "    \"Cas(sekunde)\": [trajanje],\n",
    "    \"Conv2D\": [1],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=podatki)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model.fit\n",
    "Keras pri funkciji fit hrani določene parametre, ki pa jih lahko tudi nastavljamo. V našem primeru imamo samo privzete, ki si jih lahko ogledamo s pomočjo: \n",
    "* print(history.history.keys())\n",
    "\n",
    "Privzeto vključuje:\n",
    "*   acc\n",
    "*   loss\n",
    "*   val_acc\n",
    "*   val_loss\n",
    "\n",
    "Zadevo lahko vizualiziramo za vsak model, vsako epocho, kar je prikazano v nadaljevanju. Ker pa se tokrat v nastavljanje parametrov algoritma ne spuščam, si bomo kasneje ogledali le povprečne vrednosti v skupnem grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# print((history.history['loss']))\n",
    "# print(mean(history.history['loss'])) # povprečje nad podatki v arrayu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    # Graf lossa\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(\"Cross Entropy Loss\")\n",
    "    plt.plot(histories[i].history[\"loss\"], color=\"blue\", label=\"train\")\n",
    "    plt.plot(histories[i].history[\"val_loss\"], color=\"orange\", label=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    # Graf točnsti\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title(\"Točnost klasifikacije\")\n",
    "    plt.plot(histories[i].history[\"accuracy\"], color=\"blue\", label=\"train\")\n",
    "    plt.plot(histories[i].history[\"val_accuracy\"], color=\"orange\", label=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcija poljubnega podatka (s pomočjo KFold modela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "indeks_stevila = 1234  # Poljubno vstavi število med 0-9999\n",
    "plt.imshow(x_test[indeks_stevila].reshape(28, 28), cmap=\"Greys\")\n",
    "pred = modelKFold.predict(\n",
    "    x_test[indeks_stevila].reshape(1, 28, 28, 1)\n",
    ")  # Predickija števila\n",
    "print(\n",
    "    \"Napovedana: \" + str(pred.argmax()) + \" Dejanska: \" + str(y_test[indeks_stevila])\n",
    ")  # Izpise napovedano vrednost ter dejansko vrednost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nastavitev epoch za vse naslednje modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs = 3  # \"Poljubno\" nastavimo število epoch za vse vnaprej\n",
    "index_columns = [\"Ime\", \"Tocnost\", \"Loss\", \"Cas(sekunde)\", \"Conv2D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = ponastaviPodatke(\n",
    "    train_data, train_data_labels, test_data, test_data_labels\n",
    ")\n",
    "\n",
    "modelPrvi = Sequential()\n",
    "modelPrvi.add(Conv2D(28, kernel_size=(3, 3), input_shape=input_shape))\n",
    "modelPrvi.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelPrvi.add(Flatten())\n",
    "modelPrvi.add(Dense(128, activation=tf.nn.relu))\n",
    "modelPrvi.add(Dropout(0.2))\n",
    "modelPrvi.add(Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "modelPrvi.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "CasZacetek = time.time()  # čas \"Štoparice\" si zapišemo na začetku - trenutni čas\n",
    "\n",
    "history2 = modelPrvi.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=0,\n",
    ")  # Shranimo podatke fita\n",
    "\n",
    "tocnost2 = history2.history[\n",
    "    \"accuracy\"\n",
    "]  # Iz podatkov vzamemo nam zanimiva 'accuracy' - tocnost\n",
    "loss2 = history2.history[\"loss\"]  # in loss modela\n",
    "\n",
    "CasKonec = time.time()  # čas \"Štoparice\" si zapišemo še na koncu\n",
    "trajanje = (\n",
    "    CasKonec - CasZacetek\n",
    ")  # Končnemu času odštejemo začetnega - razlika med njima je trajanje učenja\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['ModelPrvi'],\n",
    "    'Tocnost' :  [mean(tocnost2) * 100],\n",
    "    'Loss' : [mean(loss2) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [1]\n",
    "} # Kreiranje vrstice za v dataframe\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df  # izpis dataframea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ena izmed lepših stvari v Pythonu je ta, da lahko model ocenimo s pomočjo ene vrstice kode. Obstaja seveda še veliko drugih metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "predictions = modelPrvi.predict(x_test)\n",
    "n = 2  # Poljubno vstavi vrednost med 0 in 9.999\n",
    "print(\"Napovedana: \" + str(np.argmax(predictions[n])) + \" Dejanska: \" + str(y_test[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loss in Točnost modela 'ModelPrvi'\")\n",
    "modelPrvi.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "Je tehnika, ki avtomatsko standardizira vhodne podatke naslednjemu sloju v globoki nevronski mreži. \n",
    "\n",
    "Po implementaciji nam pohitri proces učenja, v nekaterih primerih pa malenkost izboljša točnost modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "def UstvariModelKFoldBatch():\n",
    "    # Sestavimo model Nevronske Mreže\n",
    "    ModelKFoldBatch = Sequential()\n",
    "    ModelKFoldBatch.add(BatchNormalization())\n",
    "    ModelKFoldBatch.add(\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            input_shape=input_shape,\n",
    "        )\n",
    "    )\n",
    "    ModelKFoldBatch.add(MaxPooling2D((2, 2)))\n",
    "    ModelKFoldBatch.add(Flatten())\n",
    "    ModelKFoldBatch.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    ModelKFoldBatch.add(BatchNormalization())\n",
    "    ModelKFoldBatch.add(Dense(10, activation=\"softmax\"))\n",
    "    return ModelKFoldBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ModelKFoldBatch = UstvariModelKFoldBatch()\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "ModelKFoldBatch.compile(\n",
    "    optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "x_train, y_train, x_test, y_test = ponastaviPodatke(\n",
    "    train_data, train_data_labels, test_data, test_data_labels\n",
    ")\n",
    "\n",
    "CasZacetek = time.time()\n",
    "history3 = ModelKFoldBatch.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=0,\n",
    ")\n",
    "tocnost3 = history3.history[\"accuracy\"]\n",
    "loss3 = history3.history[\"loss\"]\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime': ['modelKFoldBatch'],\n",
    "    'Tocnost': [mean(tocnost3) * 100],\n",
    "    'Loss': [mean(loss3) * 100],\n",
    "    'Cas(sekunde)': [trajanje],\n",
    "    'Conv2D': [1]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def UstvariModel2xConv():\n",
    "    model2Conv = Sequential()\n",
    "    model2Conv.add(\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            input_shape=(28, 28, 1),\n",
    "        )\n",
    "    )\n",
    "    model2Conv.add(MaxPooling2D((2, 2)))\n",
    "    model2Conv.add(\n",
    "        Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
    "    )\n",
    "    model2Conv.add(MaxPooling2D((2, 2)))\n",
    "    model2Conv.add(Flatten())\n",
    "    model2Conv.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    model2Conv.add(Dense(10, activation=\"softmax\"))\n",
    "    return model2Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model2Conv = UstvariModel2xConv()\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model2Conv.compile(\n",
    "    optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "x_train, y_train, x_test, y_test = ponastaviPodatke(\n",
    "    train_data, train_data_labels, test_data, test_data_labels\n",
    ")\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "history4 = model2Conv.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=0,\n",
    ")\n",
    "tocnost4 = history4.history[\"accuracy\"]\n",
    "loss4 = history4.history[\"loss\"]\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['model2xConv'],\n",
    "    'Tocnost' : [mean(tocnost4) * 100],\n",
    "    'Loss' : [mean(loss4) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [2]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def UstvariModelIzboljsan():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            input_shape=(28, 28, 1),\n",
    "        )\n",
    "    )\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "modelIzboljsan = UstvariModelIzboljsan()\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "modelIzboljsan.compile(\n",
    "    optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "x_train, y_train, x_test, y_test = ponastaviPodatke(\n",
    "    train_data, train_data_labels, test_data, test_data_labels\n",
    ")\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "history5 = modelIzboljsan.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=0,\n",
    ")\n",
    "tocnost5 = history5.history[\"accuracy\"]\n",
    "loss5 = history5.history[\"loss\"]\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['model3xConv'],\n",
    "    'Tocnost' : [mean(tocnost5) * 100],\n",
    "    'Loss' : [mean(loss5) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [3]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def UstvariModel4xConv():\n",
    "    Model4xConv = Sequential()\n",
    "    Model4xConv.add(\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            input_shape=(28, 28, 1),\n",
    "        )\n",
    "    )\n",
    "    Model4xConv.add(MaxPooling2D((2, 2)))\n",
    "    Model4xConv.add(\n",
    "        Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
    "    )\n",
    "    Model4xConv.add(\n",
    "        Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
    "    )\n",
    "    Model4xConv.add(MaxPooling2D((2, 2)))\n",
    "    Model4xConv.add(\n",
    "        Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
    "    )\n",
    "    Model4xConv.add(MaxPooling2D((2, 2)))\n",
    "    Model4xConv.add(Flatten())\n",
    "    Model4xConv.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "    Model4xConv.add(Dense(10, activation=\"softmax\"))\n",
    "    return Model4xConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Model4xConv = UstvariModel4xConv()\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "Model4xConv.compile(\n",
    "    optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "x_train, y_train, x_test, y_test = ponastaviPodatke(\n",
    "    train_data, train_data_labels, test_data, test_data_labels\n",
    ")\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "history6 = Model4xConv.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=0,\n",
    ")\n",
    "tocnost6 = history6.history[\"accuracy\"]\n",
    "loss6 = history6.history[\"loss\"]\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['model4xConv'],\n",
    "    'Tocnost' : [mean(tocnost6) * 100],\n",
    "    'Loss' : [mean(loss6) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [4]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\", x=\"Ime\", y=\"Cas(sekunde)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\", x=\"Ime\", y=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\", stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uporaba Scikit Learn\n",
    "Spet imamo veliko različnih možnosti nalaganja podatkov, nek manjši digit dataset ima tudi sklearn, ima pa okoli 1700 števk velikosti 8x8 pikslov.\n",
    "Da bo primerjava realnejša, raje uporabim datoteko, ki jo že imam na disku.\n",
    "## Naslednja metoda naredi podobno kot naša preberiDatoteke() \n",
    "\n",
    "Vendar na malenkost drugačen način zapiše datoteke v spremenljivke, zmanjša dimenzijo arraya, kar omogoči uporabo sk-learn knjižnice. Tukaj namreč potrebujemo maksimalno 2D array, pri nevronskih mrežah pa je bilo dimenzij več "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "\n",
    "\n",
    "def loadmnist(imagefile, labelfile):\n",
    "\n",
    "    # Open the images with gzip in read binary mode\n",
    "    images = open(imagefile, \"rb\")\n",
    "    labels = open(labelfile, \"rb\")\n",
    "\n",
    "    # Get metadata for images\n",
    "    images.read(4)  # skip the magic_number\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack(\">I\", number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack(\">I\", rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack(\">I\", cols)[0]\n",
    "\n",
    "    # Get metadata for labels\n",
    "    labels.read(4)\n",
    "    N = labels.read(4)\n",
    "    N = unpack(\">I\", N)[0]\n",
    "\n",
    "    # Get data\n",
    "    x = np.zeros((N, rows * cols), dtype=np.uint8)  # Initialize numpy array\n",
    "    y = np.zeros(N, dtype=np.uint8)  # Initialize numpy array\n",
    "    for i in range(N):\n",
    "        for j in range(rows * cols):\n",
    "            tmp_pixel = images.read(1)  # Just a single byte\n",
    "            tmp_pixel = unpack(\">B\", tmp_pixel)[0]\n",
    "            x[i][j] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack(\">B\", tmp_label)[0]\n",
    "\n",
    "    images.close()\n",
    "    labels.close()\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Učna in testna množica\n",
    "sedaj sem mali x in y zamenjal z velikim, podatki v množici so v bistvu enaki, le na drugačen način zabeleženi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = loadmnist(\n",
    "    \"train/train-images.idx3-ubyte\", \"train/train-labels.idx1-ubyte\"\n",
    ")\n",
    "X_test, Y_test = loadmnist(\"test/t10k-images.idx3-ubyte\", \"test/t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "logisticRegr = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "logisticRegr.fit(X_train, Y_train)\n",
    "\n",
    "tocnost7 = logisticRegr.score(X_test, Y_test)\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['LogisticRegression'],\n",
    "    'Tocnost' : [mean(tocnost7) * 100],\n",
    "    'Loss' : [0],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [0]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "napovej = logisticRegr.predict(X_test)\n",
    "cm = metrics.confusion_matrix(Y_test, napovej)\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", cmap=\"magma_r\")\n",
    "plt.xlabel(\"Napovedana stevka\")\n",
    "plt.ylabel(\"Dejanska stevka\")\n",
    "all_sample_title = \"Accuracy Score: {:.0f}\".format(tocnost7)\n",
    "plt.title(all_sample_title, size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zanimivost\n",
    "Ena izmed bolj zanimiv zadev, ki sem jih zasledil, pa je vizualen prikaz števk, ki smo jih narobe napovedali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "nepravilne = []\n",
    "for label, predict in zip(Y_test, napovej):\n",
    "    if label != predict:\n",
    "        nepravilne.append(i)\n",
    "    i = i + 1\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for plotIndex, badIndex in enumerate(\n",
    "    nepravilne[0:12]\n",
    "):  # s for zanko se sprehodimo čez prvih dvanajst 0-11\n",
    "    plt.subplot(\n",
    "        3, 4, plotIndex + 1\n",
    "    )  # subplot naredi več majnših grafov, prikazuje 3 vrstice in 4 stolpce sličic\n",
    "    plt.imshow(\n",
    "        np.reshape(X_test[badIndex], (28, 28)), cmap=plt.cm.gray\n",
    "    )  # 28,28 je dejanska velikost slike\n",
    "    plt.title(\n",
    "        \"Napoved: {}, Dejansko: {}\".format(napovej[badIndex], Y_test[badIndex]),\n",
    "        fontsize=15,\n",
    "    )  # K vsaki sliki dodamo title bar, v katerega zapišemo dejansko vrednost števke ter vrednost, ki jo je naš LogisticRegression algoritem napovedal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Komentar\n",
    "Lahko vidimo, da števke ki so bile napačno napovedane, so večinoma res zmazki. Pri določenih takoj opazimo, kje se je algoritem zmotil. Spet drugje ni najbolj jasno zakaj je do tega prišlo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pac = PassiveAggressiveClassifier(max_iter=1000, random_state=0)\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "pac.fit(X_train, Y_train)\n",
    "\n",
    "tocnost8 = pac.score(X_test, Y_test)\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['PassiveAggressiveClassifier'],\n",
    "    'Tocnost' : [mean(tocnost8) * 100],\n",
    "    'Cas(sekunde)': [trajanje],\n",
    "    'Conv2D': [0]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LarsCV\n",
    "\n",
    "lCV = LarsCV()\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "lCV.fit(X_train, Y_train)\n",
    "\n",
    "tocnost9 = lCV.score(X_test, Y_test)\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['LarsCV'],\n",
    "    'Tocnost' : [mean(tocnost9) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [0]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "rCV = RidgeCV()\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "rCV.fit(X_train, Y_train)\n",
    "\n",
    "tocnost10 = rCV.score(X_test, Y_test)\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['RidgeCV'],\n",
    "    'Tocnost' : [mean(tocnost10) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [0]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "enCV = ElasticNetCV()\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "enCV.fit(X_train, Y_train)\n",
    "\n",
    "tocnost11 = enCV.score(X_test, Y_test)\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['ElasticNetCV'],\n",
    "    'Tocnost' : [mean(tocnost11) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [0]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "br = BayesianRidge()\n",
    "\n",
    "CasZacetek = time.time()\n",
    "\n",
    "br.fit(X_train, Y_train)\n",
    "\n",
    "tocnost12 = br.score(X_test, Y_test)\n",
    "\n",
    "CasKonec = time.time()\n",
    "trajanje = CasKonec - CasZacetek\n",
    "\n",
    "dodaj_vrstico = {\n",
    "    'Ime' : ['BayesianRidge'],\n",
    "    'Tocnost' : [mean(tocnost12) * 100],\n",
    "    'Cas(sekunde)' : [trajanje],\n",
    "    'Conv2D' : [0]\n",
    "}\n",
    "dodaj_vrstico_series = pd.DataFrame(dodaj_vrstico)\n",
    "df = pd.concat([df, dodaj_vrstico_series], ignore_index = True)  # Dodajanje vrstice v dataframe\n",
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zaključek\n",
    "\n",
    "### Sproti v kodi imamo par spremenljivk, ki jih lahko nastavljamo ter malo preizkušamo naše algoritme, si kaj vizualiziramo. Bralcu priporočam, da to poišče s pomočjo iskanja (ctrl + f) besedice \"poljubno\"\n",
    "### Zakaj 3 epoche?\n",
    "Kot sem že na začetku zapisal, sem se osredotočil na čas in ne na najvišjo možno točnost. Izkazalo se je, da se modeli med prvimi tremi epochami največ naučijo, razlike so najbolj očitne. Kasneje so te vrednosti bistveno manjše, čas izvajanja algoritma pa se sorazmerno podaljša.\n",
    "\n",
    "Sedaj vidimo, kako zelo natančne so nevronske mreže. Pa vendar nastopi problem, tudi če je natančnost 99.9%, to pomeni, da bi v primeru avtonomnih avtomobilov vsak tisoči naredil prometno nesrečo..\n",
    "\n",
    "Točnosti časov algoritmov so sicer izmerjene za čas treniranja, vendar vsakič znova opažam velike razlike. Do tega pride preprosto zaradi tega, ker na operacijskem sistemu python ni edini proces, kljub temu, da sem se trudil imeti ostale programe zaprte. Na windowsu imamo torej obilico ostalih procesov, ki se izvajajo v okviru OS ter na njih skoraj nimamo vpliva.\n",
    "\n",
    "Najbolj zanimiva je časovna primerjava nevronskih mrež, ki so vse zelo natančne z drugačno vrsto algoritmov. Tudi ti dosegajo dobro natačnost vendar v občutno krajšem času.\n",
    "### Pojasnilo\n",
    "ModelKFold uporablja navzkrižno (KFold) validacijo, modelKFoldBatch pa je enak model, dodana je Batch validacija, ni pa uporabljena navzkrižna validacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\", x=\"Ime\", y=\"Cas(sekunde)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pri ogledu grafa razlike med točnostjo CNN ne opazimo, njihov čas je pa bistveno večji od Sk-learn. Vidimo, da Logistic Regression glede na porabljen čas dosega najboljše rezultate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\", stacked=True, x=\"Ime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Grafa prikazujeta točnosti in losse naših nevronskih mrež\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "df.iloc[:6].plot(ax=axes[0], kind=\"bar\", y=\"Cas(sekunde)\")\n",
    "df.iloc[:6].plot(ax=axes[1], kind=\"bar\", y=\"Loss\")\n",
    "df.iloc[:6].plot(ax=axes[2], kind=\"bar\", x=\"Ime\", y=\"Tocnost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V prejšnjem grafu vidimo primerjavo časa, lossov ter tocnosti naših CNN, ki so se vse izkazale za odlične, točnosti so si torej tako podobne, da se jih z grafa ne da razločiti. Zanimiv pa je čas treniranja. Tako kot je pisalo v članku avtorja dataseta, potrebujemo nekje od cirka 1minute za fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Graf točnosti ScikitLearn algoritmov\n",
    "df.iloc[6:].plot(kind=\"bar\", x=\"Ime\", y=\"Cas(sekunde)\")\n",
    "df.iloc[6:].plot(kind=\"bar\", x=\"Ime\", y=\"Tocnost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Komentar o SkLearn\n",
    "Notebook sem večkrat zagnal, rezultati pa so večinoma enaki. LarsCV ima v našem primeru **najslabšo natančnost**, čas pa je nekje v povprečju. \n",
    "\n",
    "Za **najbolj točnega** se običajno izkaže LogisticREgression, pri čemer pa po času zasede 3. mesto.\n",
    "\n",
    "**Daleč** največ časa porabi ElasticNetCV, njegova točnost pa je nekje okoli 3. mesta, ki si ga deli še z RidgeCV in BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Napoved lastno zapisanih števk\n",
    "Da pa ne bomo vsega prikazovali samo v teoriji na podlagi dataseta \"z interneta\", sem ustvaril svoj majhen testni dataset\n",
    "\n",
    "Moje slike so tanko napisane z modro kulico na list papirja, slikane s telefonom, namenoma niso tako \"lepe\". Original slika je, kot dokazni material, priložena v mapi rocnoNapisaneStevke, vsako števko posebej pa sem iz slike izločil ter shranil v (28,28) pikslov, saj tako zmanjšam velikost celotnega projekta.\n",
    "\n",
    "Knjižnica cv2 omogoča branje slik iz diska, s parametrom cv.IMREAD pa določamo barvno lestvico, npr. _UNCHANGED in _COLOR. Naš model je napoveal v sivinah, zato tudi mi našo sliko preberemo v sivinah. \n",
    "\n",
    "To omogoči, da lahko vsako števko, ne glede na to kako in kje je napisana, naš algoritem prebere, barve pa uredimo v kodi. Je pa res, da če bi imeli roza ozadje in rdečo števko, bi nastopil problem urejanja barv, saj niso v kontrastu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def napovejRocnoNapisane(s):\n",
    "    file = \"hand-written-digits/\" + str(s) + \".png\"  # podamo datoteko\n",
    "    image = cv.imread(\n",
    "        file, cv.IMREAD_GRAYSCALE\n",
    "    )  # preberemo datoteko kot sliko, pretvorimo v barvno lestvico sivin\n",
    "    image = image.astype(\"float32\")  # pretvorimo v tip float, s katero cnn zna delat\n",
    "    image = image.reshape(1, 28, 28)  # shape slike - enak kot pri MNIST datasetu\n",
    "    image = 255 - image  # Obrnemo barve\n",
    "    # image = ~image # Obrnemo barve\n",
    "    image = image / 255  # Normalizacija\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for s in range(10):\n",
    "    print(\"Števka \" + str(s))\n",
    "    display(Image(\"hand-written-digits/\" + str(s) + \".png\", format=\"png\"))\n",
    "\n",
    "print(\"Sledijo napovedi\")\n",
    "\n",
    "for s in range(10):\n",
    "    image = napovejRocnoNapisane(str(s))\n",
    "    plt.imshow(image.reshape(28, 28), cmap=\"Greys\")\n",
    "    plt.show()\n",
    "    pred = modelKFold.predict(image.reshape(1, 28, 28, 1))  # Predickija števila\n",
    "    print(\n",
    "        \"Napovedana: \" + str(pred.argmax()) + \" Dejanska: \" + str(s)\n",
    "    )  # Izpise napovedano vrednost ter dejansko vrednost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
